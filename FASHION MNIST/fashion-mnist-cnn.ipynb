{"cells":[{"metadata":{"_uuid":"e86fa942-86d2-4c9f-a096-27d08e54db79","_cell_guid":"479840ac-b726-4c94-9482-452c4b8b148f","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport math\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport os\nimport time\n\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.models import Sequential\nfrom keras.layers import Convolution2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Flatten\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.layers import BatchNormalization\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import Adam\n\n\ndef reformat(df):\n    labels = df.iloc[:, 0]\n    data = df.iloc[:, 1:]\n    reformatted_data = []\n    for i in range(len(data)):\n        narray = data.iloc[i, :].to_numpy().ravel()\n        narray = narray.reshape(int(math.sqrt(len(narray))), int(math.sqrt(len(narray))), 1)\n        reformatted_data.append(narray)\n\n    return labels.to_numpy().ravel(), np.array(reformatted_data).astype('float64')\n\n\ndef create_augmented_data(data, labels):\n    mirrored_images = []\n    mirrored_images_label = []\n\n    for i in range(len(data)):\n        mirrored_images.append(np.flip(data[i], 1))\n        mirrored_images_label.append(labels[i])\n\n    result = np.append(data, mirrored_images, axis=0)\n    result_label = np.append(labels, mirrored_images_label, axis=0)\n    return result_label, result\n\ndef normalize(data):\n    new_data = np.copy(data)\n    for i in range(data.shape[0]):\n        new_data[i] = new_data[i]/255\n\n    return new_data\n\ndef standardize(data):\n    new_data = np.copy(data)\n    for i in range(data.shape[0]):\n        mean = np.mean(data[i])\n        std = np.std(data[i])\n        new_data[i] = (new_data[i]-mean)/std\n\n    return new_data\n\ndef one_hot_encode(labels):\n    encoded = []\n    max_val = labels.max()\n    min_val = labels.min()\n    for data in labels:\n        r = np.zeros(max_val - min_val + 1)\n        r[data - min_val] = 1\n        encoded.append(r)\n\n    return np.array(encoded)\n\n\ndef one_hot_to_index(labels):\n    return np.argmax(labels, axis=1)\n\n\ndef calc_acc(classes, model, X, y, title):\n    correct = 0\n    incorrect = 0\n\n    x_result = model.predict(X, verbose=0)\n\n    class_correct = [0] * len(classes)\n    class_incorrect = [0] * len(classes)\n\n    for i in range(len(X)):\n        act = y[i]\n        res = x_result[i]\n\n        actual_label = int(np.argmax(act))\n        pred_label = int(np.argmax(res))\n\n        if pred_label == actual_label:\n            class_correct[actual_label] += 1\n            correct += 1\n        else:\n            class_incorrect[actual_label] += 1\n            incorrect += 1\n\n    acc = float(correct) / float(correct + incorrect)\n\n    result_string = \"\"\n    result_string += \"Current Network \" + title + \" Accuracy: %.3f \\n\\n\" % (acc)\n    result_string += \"Current Network \" + title + \" Class Accuracies:\\n\"\n    for i in range(len(classes)):\n        tot = float(class_correct[i] + class_incorrect[i])\n        class_acc = -1\n        if (tot > 0):\n            class_acc = float(class_correct[i]) / tot\n\n        result_string += \"\\t%s: %.3f\\n\" % (classes[i], class_acc)\n\n    if print_accuracy_to_file:\n        if not os.path.isdir(\"/kaggle/working/result\"):\n            os.mkdir(\"/kaggle/working/result\")\n        f = open(\"/kaggle/working/result/\" + title.lower() + \"_result.txt\", \"w+\")\n        f.write(result_string)\n        f.close()\n        print(\"Printing \" + title + \" accuracy is done!\")\n    else:\n        print(result_string)\n\n\ndef get_model():\n    classifier = Sequential()\n\n    classifier.add(Convolution2D(64, kernel_size=3, input_shape=(28, 28, 1), activation='relu', padding='same'))\n\n    classifier.add(BatchNormalization())\n\n    classifier.add(Convolution2D(64, kernel_size=3, input_shape=(28, 28, 1), activation='relu'))\n\n    classifier.add(BatchNormalization())\n\n    classifier.add(MaxPooling2D(2))\n\n    classifier.add(Dropout(0.25))\n\n    classifier.add(Convolution2D(64, kernel_size=3, input_shape=(28, 28, 1), activation='relu', padding='same'))\n\n    classifier.add(BatchNormalization())\n\n    classifier.add(Convolution2D(64, kernel_size=3, input_shape=(28, 28, 1), activation='relu'))\n\n    classifier.add(BatchNormalization())\n\n    classifier.add(MaxPooling2D(2))\n\n    classifier.add(Dropout(0.25))\n\n    classifier.add(Flatten())\n\n    classifier.add(Dense(units=512, activation='relu'))\n\n    classifier.add(BatchNormalization())\n\n    classifier.add(Dropout(0.2))\n\n    classifier.add(Dense(units=256, activation='relu'))\n\n    classifier.add(BatchNormalization())\n\n    classifier.add(Dropout(0.1))\n\n    classifier.add(Dense(units=128, activation='relu'))\n\n    classifier.add(BatchNormalization())\n\n    classifier.add(Dense(units=10, activation='softmax'))\n\n    return classifier\n\n# Settings\n\ndata_augmentation = True\n\nset_already_trained_model = False\nplot_loss = False\nsave_loss_plot = True\nprint_accuracy_to_file = True  # If false, accuracy will be printed on console\n\nclasses = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\",\n           \"Ankle boot\"]\n\n# Data Preprocess\n\nraw_train = pd.read_csv(\"/kaggle/input/fashionmnist/fashion-mnist_train.csv\")\nraw_test = pd.read_csv(\"/kaggle/input/fashionmnist/fashion-mnist_test.csv\")\nprint(\"Data loaded\")\ntrain_labels, train = reformat(raw_train)\ntest_labels, test = reformat(raw_test)\nprint(\"Data reformatted\")\n# Data Augmentation\n\nif data_augmentation:\n    train_labels, train = create_augmented_data(train, train_labels)\n\nprint(\"Data augmented\")\n    \ntrain = normalize(train)\ntest = normalize(test)\n\nprint(\"Data normalized\")\n\ntrain_labels = one_hot_encode(train_labels)\ntest_labels = one_hot_encode(test_labels)\n\nif not set_already_trained_model:\n    print(\"Training started\")\n    start_time = time.time()\n\n    # Model creation\n    classifier = get_model()\n\n    classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n    # Setting callbacks\n    checkpoint = ModelCheckpoint('/kaggle/working/weights.hdf5', monitor='val_loss', save_best_only=True)\n\n    history = classifier.fit(train,\n                             train_labels,\n                             epochs=100,\n                             shuffle=True,\n                             validation_split=1 / 6,\n                             use_multiprocessing=True,\n                             callbacks=[checkpoint])\n\n    elapsed_time = time.time() - start_time\n    print(\"Train finished in \" + str(elapsed_time) + \" seconds\")\n\n    # Plotting\n\n    if plot_loss or save_loss_plot:\n        plt.plot(history.history['loss'], label=\"Train\")\n        plt.plot(history.history['val_loss'], label=\"Validation\")\n        plt.legend()\n        if plot_loss:\n            plt.show()\n        elif save_loss_plot:\n            plt.savefig('plot.png')\n\n# Loading\n\nelse: #IF set_already_trained_model is TRUE\n    classifier = get_model()\n\n    classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n    classifier.load_weights('/kaggle/working/weights.hdf5')\n\n# Reporting\n\ncalc_acc(classes, classifier, test, test_labels, \"Test\")","execution_count":0,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}